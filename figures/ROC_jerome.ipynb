{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9affe1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This might contain a few more packages than you need\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sys import path\n",
    "from oasis.functions import gen_data, gen_sinusoidal_data, deconvolve, estimate_parameters\n",
    "from oasis.plotting import simpleaxis\n",
    "from oasis.oasis_methods import oasisAR1, oasisAR2\n",
    "from suite2p.extraction import dcnv\n",
    "import h5py as h5\n",
    "from numba import jit, prange\n",
    "from scipy.ndimage import filters\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from scipy.interpolate import interp1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877d04ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you want to run NND from Suite2p the way I have and with the same parameters, use this code:\n",
    "\n",
    "def oasis_trace(F, v, w, t, l, s, tau, fs):\n",
    "    \"\"\" spike deconvolution on a single neuron \"\"\"\n",
    "    NT = F.shape[0]\n",
    "    g = -1./(tau * fs)\n",
    "\n",
    "    it = 0\n",
    "    ip = 0\n",
    "\n",
    "    while it<NT:\n",
    "        v[ip], w[ip],t[ip],l[ip] = F[it],1,it,1\n",
    "        while ip>0:\n",
    "            if v[ip-1] * np.exp(g * l[ip-1]) > v[ip]:\n",
    "                # violation of the constraint means merging pools\n",
    "                f1 = np.exp(g * l[ip-1])\n",
    "                f2 = np.exp(2 * g * l[ip-1])\n",
    "                wnew = w[ip-1] + w[ip] * f2\n",
    "                v[ip-1] = (v[ip-1] * w[ip-1] + v[ip] * w[ip]* f1) / wnew\n",
    "                w[ip-1] = wnew\n",
    "                l[ip-1] = l[ip-1] + l[ip]\n",
    "                ip -= 1\n",
    "            else:\n",
    "                break\n",
    "        it += 1\n",
    "        ip += 1\n",
    "\n",
    "    s[t[1:ip]] = v[1:ip] - v[:ip-1] * np.exp(g * l[:ip-1])\n",
    "    return(s)\n",
    "\n",
    "#function for computing the non-regularized deconvolution\n",
    "# baseline operation\n",
    "\n",
    "#function for computing the non-regularized deconvolution\n",
    "# baseline operation\n",
    "\n",
    "def nndv(tau, fs, F, Fneu=None):\n",
    "    #tau = 1.0 # timescale of indicator\n",
    "    fs = 150.0 # sampling rate in Hz\n",
    "    neucoeff = 0.7 # neuropil coefficient\n",
    "    # for computing and subtracting baseline\n",
    "    baseline = 'maximin' # take the running max of the running min after smoothing with gaussian\n",
    "    sig_baseline = 5*10.0# in bins, standard deviation of gaussian with which to smooth\n",
    "    win_baseline = 60.0 # in seconds, window in which to compute max/min filters\n",
    "\n",
    "    ops = {'tau': tau, 'fs': fs, 'neucoeff': neucoeff,\n",
    "           'baseline': baseline, 'sig_baseline': sig_baseline, 'win_baseline': win_baseline, 'batch_size': 200}\n",
    "\n",
    "    # load traces and subtract neuropil\n",
    "    #F = f_cell['f_cell'][()]\n",
    "    #Fneu = f_cell['f_np'][()]\n",
    "    if Fneu:\n",
    "        Fc = F - ops['neucoeff'] * Fneu\n",
    "    else:\n",
    "        Fc = F\n",
    "\n",
    "    Fc = dcnv.preprocess(\n",
    "         F=Fc,\n",
    "         baseline=ops['baseline'],\n",
    "         win_baseline=ops['win_baseline'],\n",
    "         sig_baseline=ops['sig_baseline'],\n",
    "         fs=ops['fs'],\n",
    "         prctile_baseline=8.0\n",
    "     )\n",
    "\n",
    "    Fc=Fc.ravel()\n",
    "\n",
    "    NT = Fc.shape[0]\n",
    "    Fc = Fc.astype(np.float32)\n",
    "\n",
    "    v = np.zeros(NT, dtype=np.float32)\n",
    "    w = np.zeros(NT, dtype=np.float32)\n",
    "    t = np.zeros(NT, dtype=np.int64)\n",
    "    l = np.zeros(NT, dtype=np.float32)\n",
    "    s = np.zeros(NT, dtype=np.float32)\n",
    "\n",
    "    spikes_nndv = oasis_trace(F=Fc, v=v, w=w, t=t, l=l, s=s, tau=ops['tau'], fs=ops['fs'])\n",
    "    return spikes_nndv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cafb5ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here is how I ran the NND algorithm on all of the results for the 80 recordings of the final dataset and saved the results\n",
    "#It is important though, that you use the correct values for the various genotypes. You probably just want the one for tet-O!\n",
    "\n",
    "#Load the dff data - I had it in a dictionary of the form {recordingid(tif), np.array w/ dff values}, adjust as needed. I resampled all recordings to exactly 150 Hz:\n",
    "dff_150hz = np.load('/home/peterl/dff_resampled_dict.npy', allow_pickle=True).item()\n",
    "\n",
    "tau_dict = {'Emx1-s': 0.46594163866468175, 'tetO-s': 0.9622924335325923, 'Emx1-f': 0.16341948426755523, 'Cux2-f': 0.12241159191308901}\n",
    "\n",
    "nndv_150hz_dict = {} #nndv spikes resampled dictionary - name as needed:\n",
    "for tid, dff in dff_150hz.items(): \n",
    "    if tid in r2c.tid.unique().tolist():#just to select the recordings to run this on, you probably don't need this, since you only have four recordings\n",
    "\n",
    "        gt = r2c[r2c.tid==tid].gtype.values[0]#determine the genotype - you don't need that if you only have one. r2c is a pandas dataframe that contains the correspondence between recordings (tidoasis), cells, animals, and genotype. You prbably don't need it.\n",
    "\n",
    "        tau = np.exp(-1/(tau_dict[gt] * 150)) #set the frame rate! mine was 150.\n",
    "        print(tau)\n",
    "        nndv_spikes = nndv(tau, 1.0/150., dff[np.newaxis, :])\n",
    "        nndv_150hz_dict[tid] = nndv_spikes\n",
    "#save        \n",
    "np.save('/home/peterl/nndv_150hz_dict', nndv_150hz_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7798254",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your dictionaries of ground truth spikes and events events:\n",
    "gt_150hz_dict = np.load('/home/peterl/gt_150hz_dict.npy', allow_pickle=True).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a246c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#helper function that rebins the events and the ground truth spikes by summation across non-overlapping window of width winsize\n",
    "def rebin(vector, winsize): # winsize must be integer\n",
    "    new_vector = np.zeros(vector.shape[0] // winsize)\n",
    "    for n, value in enumerate(new_vector):\n",
    "        new_vector[n] = np.sum(vector[n*winsize:(n+1)*winsize])\n",
    "    return new_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d4511a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are the things I've been comparing. Adapt to the names of your dictionaries.\n",
    "methods = {'g': mlspike_150hz_dict.item(), 'b': nndv_150hz_dict,'k':l0_150hz_dict.item()}\n",
    "\n",
    "##Emx1-f\n",
    "for gtype in r2c.gtype.unique(): #if you don't have different genotypes, you don't need this loop\n",
    "    #Loop over all cells in genotype\n",
    "    factors = 5*np.array([1, 3, 6, 9, 15]) #These are binning factors. I compared 33, 100, 200, 300, 500 ms bins\n",
    "\n",
    "    fig, ax = plt.subplots(nrows=1, ncols=5, sharex=True, sharey=True, figsize=(15,3))\n",
    "    \n",
    "    for k, factor in enumerate(factors):\n",
    "        ax[k].set_title(gtype + ' - bin:' + str(np.round(factor * 1000./150.)) + ' ms')\n",
    "        cellids = r2c.acid[r2c.gtype==gtype].unique()\n",
    "        for color, method in methods.items():\n",
    "            g_tpri = np.zeros((len(cellids), 100)) # g_tpri == global truth true positive rate, interpolated (averages per cell)\n",
    "\n",
    "            for j, cid in enumerate(cellids): # I computed averages over cells, not recordings - you can eliminate this loop if you are using 1 recording per cell. \n",
    "                #For each cell loop over recordings\n",
    "                tids = r2c.tid[r2c.acid==cid].unique()\n",
    "\n",
    "                tpri = np.zeros((len(tids), 100)) #true positive rate for each recording (tid)\n",
    "                for i, tid in enumerate(tids):\n",
    "                #For each recording, loop over dictionary of dictionaries containing the inference results\n",
    "                #compute ROC curves \n",
    "                    gt = rebin(gt_150hz_dict[tid].ravel(), factor) #rebin ground truth according to factor\n",
    "                    gt = gt/np.max(gt) #normalize to max\n",
    "                    test = method[tid].ravel() #load the events you are comparing\n",
    "                    test[np.isnan(test)]=0 #if any entries are nan, set to 0\n",
    "                    test = rebin(test, factor) #rebin loaded events according to factor\n",
    "                    test = test/np.max(test) #normalize events after rebinning\n",
    "                    fpr, tpr, _ = roc_curve(gt>0, test) #compute the ROC curve - does not work is ground truth is non-binary\n",
    "                    interp_fn = interp1d(fpr, tpr, kind='previous') #left-bound interpolato\n",
    "                    tpri[i,:] = interp_fn(np.linspace(0.,1., 100)) #interpolate the ROC curve for averaging\n",
    "                #plot average of interpolated ROC curves for each cell     \n",
    "                ax[k].plot(np.linspace(0.,1., 100)[:-2], tpri.mean(axis=0)[:-2], color, alpha=1, linewidth=0.2)\n",
    "                #Compute average of interpolated ROC curves for each genotype\n",
    "                g_tpri[j,:] = tpri.mean(axis=0)\n",
    "\n",
    "            #Plot average of interpolated ROC curves for each genotype\n",
    "            ax[k].plot(np.linspace(0.,1., 100)[:-2], g_tpri.mean(axis=0)[:-2], color, alpha=1)    \n",
    "        ax[k].set_xlabel('False Positive Rate')\n",
    "        ax[k].set_ylabel('True Positive Rate')\n",
    "\n",
    "        # save plots\n",
    "    plt.savefig(gtype + '_high_zoom_horizontal_line.pdf', dpi=600, facecolor='w', edgecolor='w',\n",
    "        orientation='portrait', papertype=None, format=None,\n",
    "        transparent=True, bbox_inches=None, pad_inches=0.1,\n",
    "        frameon=None, metadata=None)\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
